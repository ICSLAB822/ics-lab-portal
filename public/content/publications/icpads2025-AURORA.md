---
title: "AURORA: Adaptive Audio-Video Multi-Scale Attention Fusion for Deepfake Detection"
authors: [Jie Xu, Shan Chang and Hongzi Zhu]
venue: in Proceedings of IEEE ICPADS 2025
location: Hefei, China
year: 2025
track: Conference
topic: Deepfake Detection
tags: [Deepfake Detection, Audio-Video, Multi-modal Learning, Attention Fusion]
imageUrl: icpads2025-AURORA.png
imageCaption: "Fig. 1. Overview of the proposed network."
pdfUrl: icpads2025-AURORA.pdf
---

With the rapid advancement of generative forgery technologies, the detection of multi-modal deepfake audio-video content has become an urgent demand in cyber security and forensic analysis. However, detecting audio-video deepfakes remains challenging: forgery traces are often subtle, dispersed, and highly resolution-dependent; existing multimodal methods rely on simple concatenation or shallow interactions, leading to insufficient exploitation of cross-modal consistency. To address these issues, we propose a Cross-level Multi-modal Fusion (CLMF) framework that progressively integrates audio cues into visual representations through cross-level attention, adaptively enhancing complementary information while suppressing redundancy. In addition, we design an Adaptive Audio Feature Enhancement module (AAFE) to highlight subtle frequency domain artifacts often masked by noise, and a Multi-scale Visual Feature Enhancement module (MVFE) to capture both local texture inconsistencies and global structural distortions. These components jointly achieve robust and consistent cross-modal alignment of forgery traces, leading to significant improvements in deepfake detection performance. On the FakeAVCeleb benchmark, AURORA achieves an accuracy (ACC) of 94.32% and an area under the curve (AUC) of 93.66%, demonstrating superior performance.
