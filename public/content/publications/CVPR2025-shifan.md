---
title: "WISNet: Pseudo Label Generation on Unbalanced and Patch Annotated Waste Images"
authors: [Shifan Zhang, Hongzi Zhu, Yinan He, Minyi Guo, Ziyang Lou and Shan Chang]
venue: "in Proceedings of IEEE/CVF CVPR 2025"
location: "Nashville, US"
year: 2025
track: Conference
topic: "Computer Vision"
tags: []
imageUrl: CVPR2025-shifan.png
imageCaption: "Figure 1. (a) Examples of waste images and patch-level annotations to minimize the manpower costs; (b) examples of test waste images; (c) ground truth; (d) and (e) are the segmentation results using PANet with labels generated by a SOTA model [34] and WISNet, respectively."
pdfUrl: CVPR2025-shifan.pdf
codeUrl: https://github.com/shifan-Z/WISNet
award: ""
---

Computer-vision-based assessment on waste sorting is desired to replace manpower supervision in Shanghai city. Due to the hardness of labeling a multitude of waste images, it is infeasible to train a semantic segmentation model for this purpose directly. In this work, we construct a new dataset consisting of 12,208 waste images, upon which seed regions (i.e., patches) are annotated and classified into 21 categories in a crowdsourcing fashion. To obtain pixel-level labels to train an effective segmentation model, we propose a weakly-supervised waste image pseudo label generation scheme, called WISNet. Specifically, we train a cohesive feature extractor with contrastive prototype learning, incorporating an unsupervised classification pretext task to help the extractor focus on more discriminative regions even with the same category. Furthermore, we propose an effective iterative patch expansion method to generate accurate pixel-level pseudo labels. Given these generated pseudo labels, a few-shot segmentation model can be trained to segment waste images. We implement and deploy WISNet in real-world scenarios and conduct intensive experiments. Results show that WISNet can achieve a state-of-the-art 40.2% final segmentation mIoU on our waste benchmark, outperforming all other baselines and demonstrating its efficacy.
